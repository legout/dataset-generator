{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce dataset to partitioned Parquet\n\nThis notebook materializes a compact e-commerce dataset into partitioned Parquet files on the local filesystem. Use it as a quick sanity check for the generator and writer APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from dataset_generator import create_generator, create_writer, WriterOptions, write_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure generator\n\nWe create the built-in `ecommerce` generator with smaller volumes so the notebook runs fast. Adjust the parameters to explore different ranges or periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator(\"ecommerce\",\n",
    "    seed=7,\n",
    "    n_customers=500,\n",
    "    n_products=200,\n",
    "    orders_per_day=120,\n",
    "    order_items_mean=2.4,\n",
    "    file_rows_target=200,\n",
    "    start_date=datetime.date(2023, 1, 1),\n",
    "    end_date=datetime.date(2023, 1, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write partitioned Parquet\n\nThe writer stores dimension tables as singular Parquet files and streams orders/order_items into `year=YYYY/month=MM/day=DD` folders. The output lives under `examples/demo_output/parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"examples/demo_output/parquet\").resolve()\n",
    "writer = create_writer(\"parquet\", str(output_dir), s3=None, catalog=None, options=WriterOptions(compression=\"snappy\", file_rows_target=200))\n",
    "write_dataset(generator, writer)\n",
    "sorted(path.relative_to(output_dir.parent) for path in output_dir.rglob(\"*.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect a sample\n\nLoad one of the generated order partitions with Polars to verify schema and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_file = next(output_dir.joinpath(\"orders\").rglob(\"*.parquet\"))\n",
    "pl.read_parquet(orders_file).head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
